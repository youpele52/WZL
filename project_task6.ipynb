{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is to test whether the coil data can be used to predict some KPIs in the fineblanking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from npfeintool import FeatEx\n",
    "from npfeintool import CON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dico digit coil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading DiCo_digital_coil_M1_M2_Stempel_1_punches.db\n",
      "Finished loading all 294 segments!\n",
      "start loading DiCo_digital_coil_M2_M3_Stempel_1_punches.db\n",
      "Finished loading all 140 segments!\n",
      "start loading DiCo_digital_coil_M3_M4_Stempel_1_punches.db\n",
      "Finished loading all 246 segments!\n",
      "start loading DiCo_digital_coil_M4_M5_Stempel_1_punches.db\n",
      "Finished loading all 426 segments!\n",
      "start loading DiCo_digital_coil_M5_M6_Stempel_1_punches.db\n",
      "Finished loading all 261 segments!\n",
      "start loading DiCo_digital_coil_M6_M7_Stempel_1_punches.db\n",
      "Finished loading all 167 segments!\n",
      "start loading DiCo_digital_coil_M7_M8_Stempel_1_punches.db\n",
      "Finished loading all 207 segments!\n",
      "start loading DiCo_digital_coil_M8_M9_Stempel_1_punches.db\n",
      "Finished loading all 259 segments!\n",
      "start loading DiCo_digital_coil_M9_M10_Stempel_1_punches.db\n",
      "Finished loading all 243 segments!\n",
      "start loading DiCo_digital_coil_M10_5_M11_Stempel_1_punches.db\n",
      "Finished loading all 391 segments!\n",
      "start loading DiCo_digital_coil_M10_M10_5_Stempel_1_punches.db\n",
      "Finished loading all 141 segments!\n",
      "                   0              1              2              3  \\\n",
      "count   10500.000000   10500.000000   10500.000000   10500.000000   \n",
      "mean    13277.999140   14291.148121   14523.818539   14572.175366   \n",
      "std     28709.447025   30289.307964   30840.354176   31047.179081   \n",
      "min     -4968.721600   -4726.134920   -4828.276680   -4917.650720   \n",
      "25%       815.055560     789.520120     674.610640     674.610640   \n",
      "50%      1440.673840    1581.118760    1530.047880    1415.138400   \n",
      "75%      1798.170000    2478.051090    2794.052160    2794.052160   \n",
      "max    106225.351880  110834.498800  112353.857480  112941.172600   \n",
      "\n",
      "                   4              5              6              7  \\\n",
      "count   10500.000000   10500.000000   10500.000000   10500.000000   \n",
      "mean    14563.520068   14740.934225   14902.154050   14959.521240   \n",
      "std     31200.054182   31626.549154   32165.337767   32191.731565   \n",
      "min     -4866.579840   -5198.540560   -5709.249360   -5402.824080   \n",
      "25%       585.236600     559.701160     444.791680     483.094840   \n",
      "50%      1376.835240    1300.228920    1287.461200    1249.158040   \n",
      "75%      2797.244090    2781.284440    2449.323720    2513.162320   \n",
      "max    113413.578240  114626.511640  116005.425400  116145.870320   \n",
      "\n",
      "                   8              9  ...           2732           2733  \\\n",
      "count   10500.000000   10500.000000  ...   10500.000000   10500.000000   \n",
      "mean    15010.194496   14944.421283  ...   17563.400456   17397.434687   \n",
      "std     32333.601917   32447.038136  ...   35753.532774   35301.023749   \n",
      "min     -5722.017080   -5798.623400  ...   -7918.064920   -7317.982080   \n",
      "25%       419.256240     329.882200  ...     393.720800     342.649920   \n",
      "50%      1249.158040    1172.551720  ...    1593.886480    1657.725080   \n",
      "75%      2449.323720    2423.788280  ...    3853.772920    3815.469760   \n",
      "max    116465.063320  116937.468960  ...  122657.407520  121316.796920   \n",
      "\n",
      "                2734           2735           2736           2737  \\\n",
      "count   10500.000000   10500.000000   10500.000000   10500.000000   \n",
      "mean    17530.178848   17528.939771   17595.947198   17603.585942   \n",
      "std     35696.527307   35671.472164   35823.091971   35832.533427   \n",
      "min     -7828.690880   -7726.549120   -7739.316840   -7803.155440   \n",
      "25%       380.953080     368.185360     380.953080     419.256240   \n",
      "50%      1568.351040    1593.886480    1517.280160    1568.351040   \n",
      "75%      3793.126250    3815.469760    3866.540640    3815.469760   \n",
      "max    122402.053120  122402.053120  122874.458760  122963.832800   \n",
      "\n",
      "                2738           2739           2740           2741  \n",
      "count   10500.000000   10500.000000   10500.000000   10500.000000  \n",
      "mean    17561.115642   17543.445117   17578.389759   17656.319058  \n",
      "std     35679.002182   35708.309959   35752.120533   35908.452637  \n",
      "min     -7854.226320   -7713.781400   -7701.013680   -7701.013680  \n",
      "25%       432.023960     419.256240     393.720800     432.023960  \n",
      "50%      1568.351040    1530.047880    1555.583320    1568.351040  \n",
      "75%      3841.005200    3815.469760    3841.005200    3841.005200  \n",
      "max    122478.659440  122631.872080  122785.084720  123180.884040  \n",
      "\n",
      "[8 rows x 2742 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading first db\n",
    "names_databases1 = [\"DiCo_digital_coil_M1_M2_Stempel_1_punches\"]\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases1, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df1 = pd.DataFrame()\n",
    "    df1 = CON.load_all_segments(\"\", name)\n",
    "    df = list()\n",
    "    df.append(df1)\n",
    "    df = df\n",
    "\n",
    "# Loading 2nd db\n",
    "names_databases2 = [\"DiCo_digital_coil_M2_M3_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases2, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df2 = pd.DataFrame()\n",
    "    df2 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df2)\n",
    "    df = df\n",
    "\n",
    "\n",
    "# Loading 3rd db\n",
    "names_databases3 = [\"DiCo_digital_coil_M3_M4_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases3, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df3 = pd.DataFrame()\n",
    "    df3 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df3)\n",
    "    df = df\n",
    "\n",
    "#Loading 4th db\n",
    "names_databases4 =  [\"DiCo_digital_coil_M4_M5_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases4, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df4 = pd.DataFrame()\n",
    "    df4 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df4)\n",
    "    df = df\n",
    "\n",
    "\n",
    "#Loading 5th db\n",
    "names_databases5 =  [\"DiCo_digital_coil_M5_M6_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases5, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df5 = pd.DataFrame()\n",
    "    df5 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df5)\n",
    "    df = df\n",
    "\n",
    "\n",
    "#Loading 6th db\n",
    "names_databases6 = [\"DiCo_digital_coil_M6_M7_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases6, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df6 = pd.DataFrame()\n",
    "    df6 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df6)\n",
    "    df = df\n",
    "                    \n",
    "    \n",
    "#Loading 7th db\n",
    "names_databases7 = [\"DiCo_digital_coil_M7_M8_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases7, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df7 = pd.DataFrame()\n",
    "    df7 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df7)\n",
    "    df = df\n",
    "    \n",
    "    \n",
    "    \n",
    "#Loading 8th db\n",
    "names_databases8 = [\"DiCo_digital_coil_M8_M9_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases8, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df8 = pd.DataFrame()\n",
    "    df8 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df8)\n",
    "    df = df          \n",
    "    \n",
    "\n",
    "\n",
    "#Loading 9th db\n",
    "names_databases9 = [\"DiCo_digital_coil_M9_M10_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases9, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df9 = pd.DataFrame()\n",
    "    df9 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df9)\n",
    "    df = df          \n",
    "    \n",
    "    \n",
    "\n",
    "#Loading 10th db\n",
    "names_databases10 = [\"DiCo_digital_coil_M10_5_M11_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases10, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df10 = pd.DataFrame()\n",
    "    df10 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df10)\n",
    "    df = df  \n",
    "\n",
    "    \n",
    "\n",
    "#Loading 11th db\n",
    "names_databases11 = [\"DiCo_digital_coil_M10_M10_5_Stempel_1_punches\"]\n",
    "\n",
    "\n",
    "#current indices at which the segments should be cutted\n",
    "cutting_index = [2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500,2500]\n",
    "\n",
    "#iterating over all database files and extracting features for every single database\n",
    "for name, index in zip(names_databases11, cutting_index):\n",
    "    \n",
    "    #load data into a dataframe\n",
    "    df11 = pd.DataFrame()\n",
    "    df11 = CON.load_all_segments(\"\", name)\n",
    "    df.append(df11)\n",
    "    df = df  \n",
    "    \n",
    "   \n",
    "# merging  all the dfs                    \n",
    "df_merged = CON.merge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 2742)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2742, 10500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing columns and rows\n",
    "X2 = df_merged.T\n",
    "X2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X2.iloc[:,].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dico_feature.json file containing features from fine blanking and rolling processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = pd.read_json(\"dico_features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature from fine blanking process: median_Gegenhalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "y = dico.loc [:, 'median_Gegenhalter'].values\n",
    "\n",
    "y = np.array (y)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "y_train = sc.fit_transform(y_train)\n",
    "y_test = sc.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.2380399323440779.  \n",
      "The mean squared error for this prediction is: 0.14914712038839809.\n",
      "The root squared score for this prediction is: 0.8671806388343444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting KNN regressor to the Training set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor = KNeighborsRegressor (n_neighbors=5, metric= 'minkowski', p=2, algorithm='auto' )\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youpele/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.33010653085793695.  \n",
      "The mean squared error for this prediction is: 0.24416946755983263.\n",
      "The root squared score for this prediction is: 0.7825607855317469\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting the SVR to the dataset\n",
    "from sklearn.svm import SVR \n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature from fine blanking process: min_Stempel_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "y = dico.loc [:, 'min_Stempel_4'].values\n",
    "\n",
    "y = np.array (y)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "y_train = sc.fit_transform(y_train)\n",
    "y_test = sc.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.20192919026743117.  \n",
      "The mean squared error for this prediction is: 0.09571422256617115.\n",
      "The root squared score for this prediction is: 0.901870311375753\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting KNN regressor to the Training set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor = KNeighborsRegressor (n_neighbors=5, metric= 'minkowski', p=2, algorithm='auto' )\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youpele/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.18075787938939641.  \n",
      "The mean squared error for this prediction is: 0.07601033462868326.\n",
      "The root squared score for this prediction is: 0.9220714511452999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting the SVR to the dataset\n",
    "from sklearn.svm import SVR \n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature from fine blanking process: median_Niederhalter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "y = dico.loc [:, 'median_Niederhalter_2'].values\n",
    "\n",
    "y = np.array (y)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "y_train = sc.fit_transform(y_train)\n",
    "y_test = sc.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.2407166066382418.  \n",
      "The mean squared error for this prediction is: 0.12010317070915372.\n",
      "The root squared score for this prediction is: 0.8565065767267899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting KNN regressor to the Training set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor = KNeighborsRegressor (n_neighbors=5, metric= 'minkowski', p=2, algorithm='auto' )\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youpele/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.31434396318090724.  \n",
      "The mean squared error for this prediction is: 0.20061808632348171.\n",
      "The root squared score for this prediction is: 0.7603112739896822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting the SVR to the dataset\n",
    "from sklearn.svm import SVR \n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature from rolling process: thickness_ibf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "y = dico.loc [:, 'thickness_ibf_avg']\n",
    "y = pd.DataFrame(y).fillna(value = 0, ).values\n",
    "y = np.array (y)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "y_train = sc.fit_transform(y_train)\n",
    "y_test = sc.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.021673911454571017.  \n",
      "The mean squared error for this prediction is: 0.01592031891038823.\n",
      "The root squared score for this prediction is: 0.9829749479069008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting KNN regressor to the Training set\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor = KNeighborsRegressor (n_neighbors=5, metric= 'minkowski', p=2, algorithm='auto' )\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youpele/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error for this prediction is: 0.10933338127242569.  \n",
      "The mean squared error for this prediction is: 0.047341542043994156.\n",
      "The root squared score for this prediction is: 0.949373362179276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting the SVR to the dataset\n",
    "from sklearn.svm import SVR \n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the regression model \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred) # the best value is 0.0\n",
    "\n",
    "  \n",
    "from sklearn.metrics import r2_score\n",
    "r2_score = r2_score(y_test, y_pred) # Best possible score is 1.0\n",
    "\n",
    "\n",
    "print('The mean absolute error for this prediction is: {a}.  \\nThe mean squared error for this prediction is: {b}.\\nThe root squared score for this prediction is: {c}'.format(a=mae, b=mse,c=r2_score))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
